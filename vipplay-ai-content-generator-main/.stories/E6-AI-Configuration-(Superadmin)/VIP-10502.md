# VIP-10502: Pull New Ollama Models

**Story ID**: VIP-10502
**Story Type**: Story
**Epic**: E6-AI-Configuration-(Superadmin)
**Priority**: High
**Story Points**: 5
**Status**: ✅ Complete

## User Story

As a superadmin, I want to pull new models so that I can expand available AI capabilities

## Acceptance Criteria

- [x] **AC1**: Superadmin can pull new Ollama models via API endpoint
- [x] **AC2**: API validates model name format before pulling
- [x] **AC3**: API returns 202 Accepted status for async pull operation
- [x] **AC4**: Non-superadmin users receive 403 Forbidden error
- [x] **AC5**: Invalid model names return 400 Bad Request with error message
- [x] **AC6**: API handles FastAPI/Ollama errors gracefully

## Technical Details

**API Endpoint**: `POST /api/admin/ai/models`

**Authentication**: Requires JWT token with `superadmin` role

**Request Body**:
```json
{
  "model": "llama3.1:8b"
}
```

**Data Flow**:
```
Next.js API → FastAPI: POST /models/pull → Ollama API (pull model) → FastAPI → Next.js API → Frontend
```

**Implementation Files**:
- `app/api/admin/ai/models/route.ts` - Next.js API route (lines 71-138)
- `api-service/main.py` - FastAPI endpoint (lines 104-128)
- `api-service/services/ollama_service.py` - Ollama pull_model method (lines 168-190)

**Response Format**:
```json
{
  "message": "Model llama3.1:8b is being pulled",
  "model": "llama3.1:8b",
  "status": "pulling"
}
```

**Validation**:
- Model name must match pattern: `/^[\w\-\.]+:[\w\-\.]+$|^[\w\-\.]+$/`
- Model name is required

**Error Responses**:
- `400 Bad Request` - Invalid model name format or missing model
- `401 Unauthorized` - Missing or invalid token
- `403 Forbidden` - User is not superadmin
- `500 Internal Server Error` - Ollama pull failed
- `503 Service Unavailable` - FastAPI or Ollama unavailable

## Definition of Done

- [x] Code implemented and working
- [x] All acceptance criteria met
- [x] E2E tests written and passing (tests/e2e/e6-ai-configuration.spec.ts)
- [x] Code reviewed and approved
- [x] Merged to main branch
- [x] Documented (ARCHITECTURE.md updated)

## Notes

**Implementation Notes**:
- Next.js API route proxies to FastAPI service (not direct Ollama calls)
- FastAPI endpoint: `POST /models/pull` calls Ollama service
- No mock data - uses real Ollama API via FastAPI
- Model pull is async operation (returns 202 Accepted)
- FastAPI Swagger available at `http://localhost:8000/docs`
