# VIP-10202: Configure CrewAI Multi-Agent System

**Story ID**: VIP-10202
**Story Type**: Story
**Epic**: E3-Content-Generation-(AI)
**Priority**: High
**Story Points**: 8
**Status**: To Do

## User Story

As a developer, I want CrewAI agents configured with specialized roles so that content generation uses intelligent multi-agent workflows with research, writing, and SEO optimization capabilities

## Acceptance Criteria

- [ ] **AC1**: Content Researcher agent configured with web search and knowledge base tools
- [ ] **AC2**: Content Writer agent configured with Ollama integration and writing guidelines
- [ ] **AC3**: SEO Optimizer agent configured with keyword analysis and meta generation
- [ ] **AC4**: Agent collaboration workflow defined with task delegation
- [ ] **AC5**: Crew configuration supports all 4 content generation modes (topic, keywords, trends, spin)
- [ ] **AC6**: Agent outputs validated and logged for debugging
- [ ] **AC7**: Error handling and retry logic implemented for agent failures

## Technical Details

**Architecture:**
- **FastAPI Role**: Create and manage CrewAI agents, execute agent workflows
- **Next.js Role**: Trigger agent execution via FastAPI endpoints, store results in MongoDB
- **CrewAI Framework**: Multi-agent orchestration with role-based task delegation
- **Ollama Integration**: LLM inference for agent reasoning and content generation

**Agent Definitions:**

### 1. Content Researcher Agent (`agents/researcher.py`)

**Purpose**: Research topics, gather information from knowledge base and web sources

```python
"""
Content Researcher Agent
Gathers information, analyzes trends, and provides research briefs for content creation
"""

from crewai import Agent
from tools.search_tool import WebSearchTool
from tools.knowledge_tool import KnowledgeBaseTool
from config import settings

def create_researcher_agent() -> Agent:
    """
    Create Content Researcher agent with research tools
    """
    return Agent(
        role="Content Researcher",
        goal="Research topics thoroughly and provide comprehensive information briefs for content creation",
        backstory="""You are an expert research analyst specializing in fantasy football
        and US Varsity sports. You excel at finding relevant statistics, player analysis,
        trends, and insights from multiple sources. You provide well-organized research
        briefs that content writers can easily transform into engaging articles.""",

        tools=[
            WebSearchTool(),           # Search the web for current information
            KnowledgeBaseTool(),       # Query internal knowledge base (Weaviate)
        ],

        verbose=True,
        allow_delegation=False,      # Researcher works independently

        # LLM Configuration
        llm_config={
            "model": settings.DEFAULT_MODEL,  # llama3.1:8b for fast research
            "base_url": settings.OLLAMA_BASE_URL,
            "temperature": 0.3,        # Lower temperature for factual research
            "max_tokens": 2048,
        }
    )
```

**Researcher Tools:**

```python
# tools/search_tool.py
"""Web search tool for current information"""

from crewai_tools import BaseTool
import aiohttp

class WebSearchTool(BaseTool):
    name: str = "Web Search"
    description: str = "Search the web for current information about topics, players, teams, and trends"

    async def _run(self, query: str) -> str:
        """
        Execute web search and return relevant results
        Note: In production, integrate with Google Custom Search API or similar
        """
        # TODO: Integrate with actual search API
        # For now, return placeholder
        return f"Search results for: {query}"


# tools/knowledge_tool.py
"""Knowledge base query tool for internal articles"""

from crewai_tools import BaseTool
from services.weaviate_service import weaviate_service

class KnowledgeBaseTool(BaseTool):
    name: str = "Knowledge Base Query"
    description: str = "Query internal knowledge base for similar articles, statistics, and historical content"

    async def _run(self, query: str, limit: int = 5) -> str:
        """
        Perform semantic search in Weaviate knowledge base
        """
        try:
            results = await weaviate_service.semantic_search(
                collection_name="Articles",
                query_text=query,
                limit=limit
            )

            # Format results for agent consumption
            formatted_results = []
            for result in results:
                formatted_results.append(
                    f"Title: {result['title']}\n"
                    f"Source: {result['source']}\n"
                    f"Summary: {result['content'][:300]}...\n"
                    f"---"
                )

            return "\n".join(formatted_results)

        except Exception as e:
            return f"Error querying knowledge base: {str(e)}"
```

### 2. Content Writer Agent (`agents/writer.py`)

**Purpose**: Generate high-quality content based on research briefs and writing guidelines

```python
"""
Content Writer Agent
Creates engaging, well-structured content optimized for target audience
"""

from crewai import Agent
from config import settings

def create_writer_agent() -> Agent:
    """
    Create Content Writer agent with writing expertise
    """
    return Agent(
        role="Content Writer",
        goal="Create engaging, informative, and well-structured content that resonates with fantasy football and sports enthusiasts",
        backstory="""You are a professional sports content writer with 10+ years of experience
        in fantasy football and US Varsity sports journalism. You excel at transforming research
        into compelling narratives that educate and engage readers. You understand SEO best practices
        and write in a conversational yet authoritative tone. You always cite sources and back up
        claims with statistics.""",

        tools=[],  # Writer primarily uses LLM, no external tools needed

        verbose=True,
        allow_delegation=True,  # Can delegate research tasks to Researcher

        # LLM Configuration
        llm_config={
            "model": settings.QUALITY_MODEL,  # llama3.1:70b for high-quality writing
            "base_url": settings.OLLAMA_BASE_URL,
            "temperature": 0.7,        # Balanced creativity and coherence
            "max_tokens": 4096,        # Longer context for article generation
        }
    )
```

### 3. SEO Optimizer Agent (`agents/seo_optimizer.py`)

**Purpose**: Optimize content for search engines with keywords, meta descriptions, and readability

```python
"""
SEO Optimizer Agent
Analyzes and optimizes content for search engine visibility and user engagement
"""

from crewai import Agent
from config import settings

def create_seo_optimizer_agent() -> Agent:
    """
    Create SEO Optimizer agent with optimization expertise
    """
    return Agent(
        role="SEO Specialist",
        goal="Optimize content for search engines while maintaining readability and user engagement",
        backstory="""You are an SEO expert with deep knowledge of search engine algorithms,
        keyword optimization, and content structure. You understand how to balance keyword density
        with natural language, create compelling meta descriptions, and structure content for
        featured snippets. You use data-driven insights to improve content discoverability.""",

        tools=[],  # SEO agent uses LLM for analysis

        verbose=True,
        allow_delegation=False,

        # LLM Configuration
        llm_config={
            "model": settings.DEFAULT_MODEL,  # Fast model for SEO analysis
            "base_url": settings.OLLAMA_BASE_URL,
            "temperature": 0.4,        # Focused and analytical
            "max_tokens": 2048,
        }
    )
```

**Agent Initialization Service (`services/crew_service.py`):**

```python
"""
CrewAI Orchestration Service
Manages agent lifecycle, crew configuration, and task execution
"""

from crewai import Crew, Task
from agents.researcher import create_researcher_agent
from agents.writer import create_writer_agent
from agents.seo_optimizer import create_seo_optimizer_agent
import logging

logger = logging.getLogger(__name__)


class CrewService:
    """Singleton service for CrewAI operations"""

    def __init__(self):
        self.researcher = None
        self.writer = None
        self.seo_optimizer = None
        self._initialized = False

    def initialize(self):
        """Initialize all agents (lazy initialization)"""
        if self._initialized:
            return

        logger.info("Initializing CrewAI agents...")

        try:
            self.researcher = create_researcher_agent()
            self.writer = create_writer_agent()
            self.seo_optimizer = create_seo_optimizer_agent()

            self._initialized = True
            logger.info("CrewAI agents initialized successfully")

        except Exception as e:
            logger.error(f"Failed to initialize CrewAI agents: {e}")
            raise

    def create_content_crew(self, mode: str) -> Crew:
        """
        Create a crew for content generation based on mode

        Args:
            mode: Generation mode (topic, keywords, trends, spin)

        Returns:
            Configured Crew instance
        """
        if not self._initialized:
            self.initialize()

        # Define agents based on mode
        if mode == "spin":
            # Spinning existing article doesn't need research
            agents = [self.writer, self.seo_optimizer]
        else:
            # Topic, keywords, trends all need full research workflow
            agents = [self.researcher, self.writer, self.seo_optimizer]

        return Crew(
            agents=agents,
            verbose=True,
            process="sequential",  # Tasks execute in order
        )

    async def generate_content(
        self,
        mode: str,
        input_data: dict,
        word_count: int = 1500
    ) -> dict:
        """
        Execute content generation workflow

        Args:
            mode: Generation mode (topic, keywords, trends, spin)
            input_data: Mode-specific input data
            word_count: Target word count

        Returns:
            Generated content with metadata
        """
        try:
            crew = self.create_content_crew(mode)

            # Create tasks based on mode (will be implemented in VIP-10204-10207)
            tasks = self._create_tasks_for_mode(mode, input_data, word_count)

            # Execute crew workflow
            result = await crew.kickoff(tasks=tasks)

            return {
                "success": True,
                "content": result,
                "mode": mode,
            }

        except Exception as e:
            logger.error(f"Content generation failed: {e}")
            return {
                "success": False,
                "error": str(e),
                "mode": mode,
            }

    def _create_tasks_for_mode(self, mode: str, input_data: dict, word_count: int) -> list[Task]:
        """
        Create task sequence for given mode
        Will be fully implemented in VIP-10204-10207
        """
        # Placeholder - tasks will be defined in subsequent stories
        return []


# Global singleton instance
crew_service = CrewService()
```

**Agent Configuration (`config.py` updates):**

```python
class Settings(BaseSettings):
    # ... existing settings ...

    # CrewAI Configuration
    CREWAI_VERBOSE: bool = True
    CREWAI_PROCESS: str = "sequential"  # or "hierarchical"

    # Agent-specific models
    RESEARCHER_MODEL: str = "llama3.1:8b"  # Fast model for research
    WRITER_MODEL: str = "llama3.1:70b"     # Quality model for writing
    SEO_MODEL: str = "llama3.1:8b"         # Fast model for SEO analysis

    # Agent LLM parameters
    RESEARCHER_TEMPERATURE: float = 0.3
    WRITER_TEMPERATURE: float = 0.7
    SEO_TEMPERATURE: float = 0.4
```

**Health Check Updates (`main.py`):**

```python
@app.get("/health")
async def health_check():
    """Health check with CrewAI agent status"""
    try:
        weaviate_status = weaviate_service.is_ready()
        ollama_status = True  # Will be implemented in VIP-10203

        # Check CrewAI agents
        crewai_status = crew_service._initialized

        return JSONResponse(
            status_code=200 if all([weaviate_status, ollama_status, crewai_status]) else 503,
            content={
                "status": "healthy" if all([weaviate_status, ollama_status, crewai_status]) else "degraded",
                "services": {
                    "weaviate": "up" if weaviate_status else "down",
                    "ollama": "up" if ollama_status else "down",
                    "crewai_agents": "initialized" if crewai_status else "not_initialized",
                }
            }
        )
    except Exception as e:
        logger.error(f"Health check failed: {e}")
        return JSONResponse(
            status_code=503,
            content={"status": "unhealthy", "error": str(e)}
        )
```

**Agent Testing:**

```python
# tests/test_agents.py
"""Test CrewAI agent configuration"""

import pytest
from agents.researcher import create_researcher_agent
from agents.writer import create_writer_agent
from agents.seo_optimizer import create_seo_optimizer_agent

def test_researcher_agent_creation():
    """Test researcher agent can be created"""
    agent = create_researcher_agent()
    assert agent.role == "Content Researcher"
    assert len(agent.tools) == 2  # WebSearchTool, KnowledgeBaseTool
    assert agent.allow_delegation == False

def test_writer_agent_creation():
    """Test writer agent can be created"""
    agent = create_writer_agent()
    assert agent.role == "Content Writer"
    assert agent.allow_delegation == True  # Writer can delegate to Researcher

def test_seo_optimizer_agent_creation():
    """Test SEO optimizer agent can be created"""
    agent = create_seo_optimizer_agent()
    assert agent.role == "SEO Specialist"
    assert agent.allow_delegation == False
```

**Integration with Next.js:**

Next.js will trigger agent workflows via FastAPI endpoints (to be implemented in VIP-10204-10207):

```typescript
// Example from Next.js (future implementation)
const FASTAPI_URL = process.env.FASTAPI_URL || 'http://localhost:8000';

const response = await fetch(`${FASTAPI_URL}/api/content/generate`, {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    mode: 'topic',
    input_text: 'Fantasy Football Week 10 Waiver Wire Targets',
    word_count: 1500,
    // Next.js provides job_id, user_id, etc.
    job_id: '...',
    user_id: '...',
  })
});

// FastAPI returns generated content
// Next.js stores result in MongoDB
```

## Definition of Done

- [ ] All three agents (researcher, writer, SEO optimizer) created in `agents/` folder
- [ ] Agent tools implemented (WebSearchTool, KnowledgeBaseTool)
- [ ] CrewService implemented with agent initialization and crew creation
- [ ] Agent configuration added to config.py
- [ ] Health check updated to include CrewAI status
- [ ] Agent unit tests written and passing
- [ ] Integration test with Ollama models successful
- [ ] Documentation added for agent roles and capabilities
- [ ] Code reviewed and approved
- [ ] Merged to dev branch

## Notes

**Implementation Status**: ⏳ Depends on VIP-10201 (FastAPI setup)

**Agent Architecture Pattern**:
```
User Request (Next.js)
    ↓
FastAPI /api/content/generate endpoint
    ↓
CrewService.generate_content()
    ↓
Task 1: Researcher Agent
    → WebSearchTool (external search)
    → KnowledgeBaseTool (Weaviate semantic search)
    → Output: Research brief
    ↓
Task 2: Writer Agent
    → Receives research brief
    → Uses Ollama (llama3.1:70b) for content generation
    → Output: Draft article
    ↓
Task 3: SEO Optimizer Agent
    → Analyzes draft article
    → Generates keywords, meta description, SEO score
    → Output: Optimized article + metadata
    ↓
FastAPI returns result to Next.js
    ↓
Next.js stores in MongoDB
```

**Agent Collaboration:**
- **Sequential Process**: Researcher → Writer → SEO (each agent builds on previous output)
- **Delegation**: Writer can delegate additional research tasks to Researcher
- **No Parallelization**: Tasks execute in order for coherent content flow

**Model Selection Rationale:**
- **Researcher**: Uses `llama3.1:8b` (fast model) for quick information gathering
- **Writer**: Uses `llama3.1:70b` (quality model) for high-quality content generation
- **SEO Optimizer**: Uses `llama3.1:8b` (fast model) for analytical tasks

**Error Handling:**
- Agent failures logged with full context
- Retry logic with exponential backoff (max 3 retries)
- Fallback to simpler models if quality model unavailable
- Graceful degradation (continue with available agents if one fails)

**Next Stories:**
- VIP-10203: Ollama Integration (OllamaService for LLM inference)
- VIP-10204: Topic-Based Content Generation (full task definitions)
- VIP-10205-10207: Other generation modes (keywords, trends, spin)

**Tools Implementation Priority:**
1. **KnowledgeBaseTool** (High): Essential for internal knowledge base queries
2. **WebSearchTool** (Medium): Can be placeholder initially, integrate Google Custom Search API later
3. Future tools: TrendAnalysisTool, CompetitorAnalysisTool
