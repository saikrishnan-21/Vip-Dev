# VIP-10210: Readability Analysis & Scoring

**Story ID**: VIP-10210
**Story Type**: Story
**Epic**: E3-Content-Generation-(AI)
**Priority**: Medium
**Story Points**: 3
**Status**: To Do

## User Story

As a content creator, I want detailed readability analysis for all generated content so that I can ensure articles are easy to read and engaging for my target audience with appropriate reading level adjustments

## Acceptance Criteria

- [ ] **AC1**: Calculate Flesch-Kincaid Reading Ease score (0-100)
- [ ] **AC2**: Determine Flesch-Kincaid Grade Level and reading difficulty
- [ ] **AC3**: Analyze sentence complexity (average length, variation)
- [ ] **AC4**: Evaluate paragraph structure and word usage
- [ ] **AC5**: Provide target audience mapping (grade level to reader type)
- [ ] **AC6**: Generate actionable readability improvement suggestions
- [ ] **AC7**: Store readability metrics in MongoDB for tracking

## Technical Details

**Architecture:**
- **FastAPI Role**: Calculate readability metrics, analyze text complexity, generate improvement suggestions
- **Next.js Role**: Store readability analysis in MongoDB, display metrics in UI, track improvements
- **Data Flow**: Next.js → FastAPI (content for analysis) → Readability metrics → Next.js → MongoDB

**Readability Analysis Workflow:**

```
Generated Content (from VIP-10204-10207):
- Article markdown content
- Word count and sentence count
    ↓
Next.js calls FastAPI /api/readability/analyze
    ↓
FastAPI ReadabilityService.analyze_content()
    ↓
Metric 1: Flesch-Kincaid Reading Ease (0-100)
  → Formula: 206.835 - 1.015 × (words/sentences) - 84.6 × (syllables/words)
  → Higher score = easier to read
  → Target: 60-70 (8th-9th grade, conversational)
    ↓
Metric 2: Flesch-Kincaid Grade Level
  → Formula: 0.39 × (words/sentences) + 11.8 × (syllables/words) - 15.59
  → Grade level required to understand text
  → Target: 8-10 (middle school to high school)
    ↓
Metric 3: Sentence Complexity Analysis
  → Average words per sentence (target: 15-20)
  → Sentence length variation (good: 10-30 range)
  → Long sentence count (>25 words: red flag)
  → Short sentence count (<10 words: engagement)
    ↓
Metric 4: Word Complexity Analysis
  → Average syllables per word (target: 1.5-2.0)
  → Complex word percentage (3+ syllables)
  → Passive voice detection
  → Transition word usage
    ↓
Metric 5: Paragraph Structure
  → Average words per paragraph (target: 50-100)
  → Paragraph count adequacy
  → Wall-of-text detection (200+ word paragraphs)
    ↓
Metric 6: Engagement Indicators
  → Question count (engagement technique)
  → List/bullet point usage
  → Subheading frequency
    ↓
Generate Target Audience Mapping
    ↓
Generate Improvement Suggestions
    ↓
FastAPI returns readability analysis JSON to Next.js
    ↓
Next.js stores in MongoDB generated_content collection
    ↓
Display in UI with visual breakdown
```

**Readability Service (`services/readability_service.py` - NEW):**

```python
"""
Readability Analysis Service
Comprehensive readability scoring and text complexity analysis
"""

import re
from typing import Dict, List, Tuple
from dataclasses import dataclass
import logging

logger = logging.getLogger(__name__)


@dataclass
class ReadabilityResult:
    """Readability analysis result data class"""
    flesch_reading_ease: float
    flesch_grade_level: float
    reading_level: str
    target_audience: str
    sentence_metrics: Dict
    word_metrics: Dict
    paragraph_metrics: Dict
    engagement_metrics: Dict
    improvements: List[str]
    score_interpretation: str


class ReadabilityService:
    """Service for comprehensive readability analysis"""

    def __init__(self):
        self.vowels = set('aeiouy')

    async def analyze_content(self, content: str) -> ReadabilityResult:
        """
        Perform comprehensive readability analysis

        Args:
            content: Full article markdown content

        Returns:
            ReadabilityResult with all metrics and recommendations
        """
        logger.info("Analyzing readability for content")

        # Clean content (remove markdown formatting for analysis)
        clean_text = self._clean_markdown(content)

        # Extract basic counts
        words = clean_text.split()
        word_count = len(words)
        sentences = self._split_sentences(clean_text)
        sentence_count = len(sentences)
        syllable_count = self._count_syllables(clean_text)

        # Calculate Flesch-Kincaid metrics
        flesch_reading_ease = self._calculate_flesch_reading_ease(
            word_count, sentence_count, syllable_count
        )
        flesch_grade_level = self._calculate_flesch_grade_level(
            word_count, sentence_count, syllable_count
        )

        # Determine reading level and target audience
        reading_level = self._get_reading_level(flesch_reading_ease)
        target_audience = self._get_target_audience(flesch_grade_level)

        # Analyze sentence complexity
        sentence_metrics = self._analyze_sentences(sentences, word_count)

        # Analyze word complexity
        word_metrics = self._analyze_words(words, word_count, syllable_count)

        # Analyze paragraph structure
        paragraph_metrics = self._analyze_paragraphs(content)

        # Analyze engagement indicators
        engagement_metrics = self._analyze_engagement(content)

        # Generate improvement suggestions
        improvements = self._generate_improvements(
            flesch_reading_ease,
            flesch_grade_level,
            sentence_metrics,
            word_metrics,
            paragraph_metrics,
            engagement_metrics
        )

        # Score interpretation
        score_interpretation = self._interpret_score(flesch_reading_ease)

        return ReadabilityResult(
            flesch_reading_ease=round(flesch_reading_ease, 1),
            flesch_grade_level=round(flesch_grade_level, 1),
            reading_level=reading_level,
            target_audience=target_audience,
            sentence_metrics=sentence_metrics,
            word_metrics=word_metrics,
            paragraph_metrics=paragraph_metrics,
            engagement_metrics=engagement_metrics,
            improvements=improvements,
            score_interpretation=score_interpretation
        )

    def _clean_markdown(self, content: str) -> str:
        """Remove markdown formatting for analysis"""
        # Remove headings
        text = re.sub(r'^#{1,6}\s+', '', content, flags=re.MULTILINE)
        # Remove bold/italic
        text = re.sub(r'[*_]{1,2}([^*_]+)[*_]{1,2}', r'\1', text)
        # Remove links
        text = re.sub(r'\[([^\]]+)\]\([^\)]+\)', r'\1', text)
        # Remove lists
        text = re.sub(r'^\s*[-*+]\s+', '', text, flags=re.MULTILINE)
        text = re.sub(r'^\s*\d+\.\s+', '', text, flags=re.MULTILINE)
        # Remove code blocks
        text = re.sub(r'```[^`]+```', '', text)
        text = re.sub(r'`[^`]+`', '', text)
        return text.strip()

    def _split_sentences(self, text: str) -> List[str]:
        """Split text into sentences"""
        # Split on sentence endings
        sentences = re.split(r'[.!?]+', text)
        # Filter empty and very short
        sentences = [s.strip() for s in sentences if len(s.strip()) > 10]
        return sentences

    def _count_syllables(self, text: str) -> int:
        """Count syllables in text"""
        words = text.lower().split()
        total_syllables = 0

        for word in words:
            # Remove non-alphabetic characters
            word = re.sub(r'[^a-z]', '', word)
            if not word:
                continue

            # Count vowel groups
            syllables = 0
            previous_was_vowel = False

            for char in word:
                is_vowel = char in self.vowels
                if is_vowel and not previous_was_vowel:
                    syllables += 1
                previous_was_vowel = is_vowel

            # Adjust for silent 'e'
            if word.endswith('e'):
                syllables = max(1, syllables - 1)

            # Every word has at least one syllable
            if syllables == 0:
                syllables = 1

            total_syllables += syllables

        return total_syllables

    def _calculate_flesch_reading_ease(
        self,
        word_count: int,
        sentence_count: int,
        syllable_count: int
    ) -> float:
        """
        Calculate Flesch Reading Ease score (0-100)

        Higher score = easier to read
        90-100: Very Easy (5th grade)
        80-89: Easy (6th grade)
        70-79: Fairly Easy (7th grade)
        60-69: Standard (8th-9th grade)
        50-59: Fairly Difficult (10th-12th grade)
        30-49: Difficult (College)
        0-29: Very Difficult (College graduate)
        """
        if word_count == 0 or sentence_count == 0:
            return 0.0

        avg_words_per_sentence = word_count / sentence_count
        avg_syllables_per_word = syllable_count / word_count

        score = 206.835 - (1.015 * avg_words_per_sentence) - (84.6 * avg_syllables_per_word)

        # Clamp to 0-100 range
        return max(0.0, min(100.0, score))

    def _calculate_flesch_grade_level(
        self,
        word_count: int,
        sentence_count: int,
        syllable_count: int
    ) -> float:
        """
        Calculate Flesch-Kincaid Grade Level

        Returns U.S. grade level required to understand text
        Lower grade level = easier to read
        Target: 8-10 (middle school to high school)
        """
        if word_count == 0 or sentence_count == 0:
            return 0.0

        avg_words_per_sentence = word_count / sentence_count
        avg_syllables_per_word = syllable_count / word_count

        grade_level = (0.39 * avg_words_per_sentence) + (11.8 * avg_syllables_per_word) - 15.59

        return max(0.0, grade_level)

    def _get_reading_level(self, flesch_score: float) -> str:
        """Get reading level from Flesch Reading Ease score"""
        if flesch_score >= 90:
            return "Very Easy (5th grade)"
        elif flesch_score >= 80:
            return "Easy (6th grade)"
        elif flesch_score >= 70:
            return "Fairly Easy (7th grade)"
        elif flesch_score >= 60:
            return "Standard (8th-9th grade)"
        elif flesch_score >= 50:
            return "Fairly Difficult (10th-12th grade)"
        elif flesch_score >= 30:
            return "Difficult (College)"
        else:
            return "Very Difficult (College graduate)"

    def _get_target_audience(self, grade_level: float) -> str:
        """Map grade level to target audience"""
        if grade_level <= 6:
            return "General public, very accessible"
        elif grade_level <= 8:
            return "General public, conversational content"
        elif grade_level <= 10:
            return "High school students, mainstream audience"
        elif grade_level <= 12:
            return "Educated adults, professional content"
        elif grade_level <= 16:
            return "College-educated professionals"
        else:
            return "Academic/technical specialists"

    def _analyze_sentences(self, sentences: List[str], word_count: int) -> Dict:
        """Analyze sentence complexity"""
        if not sentences:
            return {
                "count": 0,
                "avg_words_per_sentence": 0,
                "longest_sentence": 0,
                "shortest_sentence": 0,
                "long_sentence_count": 0,
                "short_sentence_count": 0,
                "variation_score": 0
            }

        sentence_lengths = [len(s.split()) for s in sentences]
        avg_length = sum(sentence_lengths) / len(sentence_lengths)

        long_sentences = sum(1 for length in sentence_lengths if length > 25)
        short_sentences = sum(1 for length in sentence_lengths if length < 10)

        # Calculate variation (good writing has variety)
        length_variance = max(sentence_lengths) - min(sentence_lengths)
        variation_score = min(100, (length_variance / 30) * 100)  # 30+ word range = 100

        return {
            "count": len(sentences),
            "avg_words_per_sentence": round(avg_length, 1),
            "longest_sentence": max(sentence_lengths),
            "shortest_sentence": min(sentence_lengths),
            "long_sentence_count": long_sentences,
            "short_sentence_count": short_sentences,
            "variation_score": round(variation_score, 1),
            "optimal_avg": 15 <= avg_length <= 20
        }

    def _analyze_words(self, words: List[str], word_count: int, syllable_count: int) -> Dict:
        """Analyze word complexity"""
        if not words:
            return {
                "count": 0,
                "avg_syllables_per_word": 0,
                "complex_word_count": 0,
                "complex_word_percentage": 0
            }

        # Complex words = 3+ syllables
        complex_words = 0
        for word in words:
            clean_word = re.sub(r'[^a-zA-Z]', '', word.lower())
            if clean_word and self._count_syllables(clean_word) >= 3:
                complex_words += 1

        avg_syllables = syllable_count / word_count
        complex_percentage = (complex_words / word_count) * 100

        return {
            "count": word_count,
            "avg_syllables_per_word": round(avg_syllables, 2),
            "complex_word_count": complex_words,
            "complex_word_percentage": round(complex_percentage, 1),
            "optimal_avg_syllables": 1.5 <= avg_syllables <= 2.0,
            "optimal_complex_percentage": complex_percentage <= 20
        }

    def _analyze_paragraphs(self, content: str) -> Dict:
        """Analyze paragraph structure"""
        # Extract paragraphs (non-heading blocks)
        paragraphs = []
        for block in content.split('\n\n'):
            block = block.strip()
            if block and not block.startswith('#'):
                paragraphs.append(block)

        if not paragraphs:
            return {
                "count": 0,
                "avg_words_per_paragraph": 0,
                "longest_paragraph": 0,
                "wall_of_text_count": 0
            }

        paragraph_lengths = [len(p.split()) for p in paragraphs]
        avg_length = sum(paragraph_lengths) / len(paragraph_lengths)

        # Wall of text = 200+ words
        wall_of_text = sum(1 for length in paragraph_lengths if length > 200)

        return {
            "count": len(paragraphs),
            "avg_words_per_paragraph": round(avg_length, 1),
            "longest_paragraph": max(paragraph_lengths),
            "wall_of_text_count": wall_of_text,
            "optimal_avg": 50 <= avg_length <= 100
        }

    def _analyze_engagement(self, content: str) -> Dict:
        """Analyze engagement indicators"""
        # Question count
        question_count = len(re.findall(r'\?', content))

        # List usage
        bullet_lists = len(re.findall(r'^\s*[-*+]\s+', content, re.MULTILINE))
        numbered_lists = len(re.findall(r'^\s*\d+\.\s+', content, re.MULTILINE))

        # Subheadings (H2, H3)
        h2_count = len(re.findall(r'^##\s+', content, re.MULTILINE))
        h3_count = len(re.findall(r'^###\s+', content, re.MULTILINE))

        return {
            "question_count": question_count,
            "bullet_lists": bullet_lists,
            "numbered_lists": numbered_lists,
            "total_lists": bullet_lists + numbered_lists,
            "h2_headings": h2_count,
            "h3_headings": h3_count,
            "total_subheadings": h2_count + h3_count
        }

    def _generate_improvements(
        self,
        flesch_score: float,
        grade_level: float,
        sentence_metrics: Dict,
        word_metrics: Dict,
        paragraph_metrics: Dict,
        engagement_metrics: Dict
    ) -> List[str]:
        """Generate actionable improvement suggestions"""
        improvements = []

        # Reading ease improvements
        if flesch_score < 60:
            improvements.append(
                f"Readability score is {flesch_score:.1f} (Fairly Difficult). "
                "Simplify language and shorten sentences to improve."
            )

        # Grade level improvements
        if grade_level > 10:
            improvements.append(
                f"Grade level is {grade_level:.1f} (too high). "
                "Target 8-10 for mainstream audience."
            )

        # Sentence improvements
        if sentence_metrics.get("avg_words_per_sentence", 0) > 20:
            improvements.append(
                f"Average sentence length is {sentence_metrics['avg_words_per_sentence']} words. "
                "Break up long sentences (target: 15-20 words)."
            )

        if sentence_metrics.get("long_sentence_count", 0) > 3:
            improvements.append(
                f"Found {sentence_metrics['long_sentence_count']} sentences over 25 words. "
                "Consider splitting these for better readability."
            )

        if sentence_metrics.get("variation_score", 0) < 50:
            improvements.append(
                "Sentence length variation is low. Mix short and long sentences for rhythm."
            )

        # Word improvements
        if word_metrics.get("complex_word_percentage", 0) > 20:
            improvements.append(
                f"Complex words: {word_metrics['complex_word_percentage']}%. "
                "Replace complex words with simpler alternatives where possible."
            )

        if word_metrics.get("avg_syllables_per_word", 0) > 2.0:
            improvements.append(
                "Use shorter, simpler words to improve readability."
            )

        # Paragraph improvements
        if paragraph_metrics.get("wall_of_text_count", 0) > 0:
            improvements.append(
                f"Found {paragraph_metrics['wall_of_text_count']} paragraphs over 200 words. "
                "Break these into smaller chunks."
            )

        if paragraph_metrics.get("avg_words_per_paragraph", 0) > 100:
            improvements.append(
                "Average paragraph length is high. Aim for 50-100 words per paragraph."
            )

        # Engagement improvements
        if engagement_metrics.get("total_lists", 0) == 0:
            improvements.append(
                "Add bullet points or numbered lists to improve scannability."
            )

        if engagement_metrics.get("total_subheadings", 0) < 3:
            improvements.append(
                "Add more subheadings (H2/H3) to break up content and improve structure."
            )

        if not improvements:
            improvements.append("Readability is good! No major improvements needed.")

        return improvements

    def _interpret_score(self, flesch_score: float) -> str:
        """Provide interpretation of Flesch Reading Ease score"""
        if flesch_score >= 80:
            return "Excellent! Very easy to read. Suitable for all audiences including children."
        elif flesch_score >= 70:
            return "Good! Fairly easy to read. Suitable for most audiences."
        elif flesch_score >= 60:
            return "Standard readability. Suitable for mainstream adult audience."
        elif flesch_score >= 50:
            return "Fairly difficult. May require some effort for average readers."
        elif flesch_score >= 30:
            return "Difficult. Suitable for educated adults and professionals."
        else:
            return "Very difficult. Best for academic or technical specialists."


# Singleton instance
readability_service = ReadabilityService()
```

**Update Content Router (`routers/readability.py` - NEW):**

```python
"""
Readability Analysis Router
Comprehensive readability scoring endpoints
"""

from fastapi import APIRouter, HTTPException
from pydantic import BaseModel, Field
from services.readability_service import readability_service, ReadabilityResult
from typing import Dict, List

router = APIRouter(prefix="/api/readability", tags=["readability"])


class ReadabilityAnalysisRequest(BaseModel):
    """Request model for readability analysis"""
    content: str = Field(..., min_length=100, description="Article content (markdown)")


class ReadabilityAnalysisResponse(BaseModel):
    """Response model for readability analysis"""
    flesch_reading_ease: float
    flesch_grade_level: float
    reading_level: str
    target_audience: str
    sentence_metrics: Dict
    word_metrics: Dict
    paragraph_metrics: Dict
    engagement_metrics: Dict
    improvements: List[str]
    score_interpretation: str


@router.post("/analyze", response_model=ReadabilityAnalysisResponse)
async def analyze_readability(request: ReadabilityAnalysisRequest):
    """
    Analyze content readability

    Calculates:
    - Flesch Reading Ease (0-100, higher = easier)
    - Flesch-Kincaid Grade Level (U.S. grade required)
    - Sentence complexity metrics
    - Word complexity metrics
    - Paragraph structure
    - Engagement indicators

    Returns:
    - Comprehensive readability metrics
    - Target audience mapping
    - Actionable improvement suggestions
    """
    try:
        result: ReadabilityResult = await readability_service.analyze_content(
            content=request.content
        )

        return ReadabilityAnalysisResponse(
            flesch_reading_ease=result.flesch_reading_ease,
            flesch_grade_level=result.flesch_grade_level,
            reading_level=result.reading_level,
            target_audience=result.target_audience,
            sentence_metrics=result.sentence_metrics,
            word_metrics=result.word_metrics,
            paragraph_metrics=result.paragraph_metrics,
            engagement_metrics=result.engagement_metrics,
            improvements=result.improvements,
            score_interpretation=result.score_interpretation
        )

    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Readability analysis failed: {str(e)}"
        )
```

**Integration with Next.js (`app/api/content/readability/route.ts` - NEW):**

```typescript
import { NextRequest, NextResponse } from 'next/server';
import { getServerSession } from 'next-auth';
import { authOptions } from '@/lib/auth';
import { getDb } from '@/lib/mongodb';
import { ObjectId } from 'mongodb';

/**
 * POST /api/content/readability
 * Analyze generated content for readability and store results
 */
export async function POST(request: NextRequest) {
  const session = await getServerSession(authOptions);
  if (!session) {
    return NextResponse.json({ error: 'Unauthorized' }, { status: 401 });
  }

  try {
    const body = await request.json();
    const { contentId } = body;

    if (!contentId) {
      return NextResponse.json(
        { error: 'Content ID is required' },
        { status: 400 }
      );
    }

    // Fetch content from MongoDB
    const db = await getDb();
    const content = await db.collection('generated_content').findOne({
      _id: new ObjectId(contentId),
      userId: new ObjectId(session.user.id)
    });

    if (!content) {
      return NextResponse.json(
        { error: 'Content not found' },
        { status: 404 }
      );
    }

    // Call FastAPI for readability analysis
    const fastapiResponse = await fetch(
      `${process.env.FASTAPI_URL}/api/readability/analyze`,
      {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          content: content.content
        })
      }
    );

    if (!fastapiResponse.ok) {
      throw new Error('FastAPI readability analysis failed');
    }

    const readabilityAnalysis = await fastapiResponse.json();

    // Store readability analysis in MongoDB
    await db.collection('generated_content').updateOne(
      { _id: new ObjectId(contentId) },
      {
        $set: {
          readabilityAnalysis: {
            fleschReadingEase: readabilityAnalysis.flesch_reading_ease,
            fleschGradeLevel: readabilityAnalysis.flesch_grade_level,
            readingLevel: readabilityAnalysis.reading_level,
            targetAudience: readabilityAnalysis.target_audience,
            sentenceMetrics: readabilityAnalysis.sentence_metrics,
            wordMetrics: readabilityAnalysis.word_metrics,
            paragraphMetrics: readabilityAnalysis.paragraph_metrics,
            engagementMetrics: readabilityAnalysis.engagement_metrics,
            improvements: readabilityAnalysis.improvements,
            scoreInterpretation: readabilityAnalysis.score_interpretation,
            analyzedAt: new Date()
          }
        }
      }
    );

    return NextResponse.json({
      success: true,
      readabilityAnalysis
    });

  } catch (error) {
    console.error('Readability analysis error:', error);
    return NextResponse.json(
      { error: 'Readability analysis failed' },
      { status: 500 }
    );
  }
}
```

## Definition of Done

- [ ] ReadabilityService implemented with Flesch-Kincaid formulas
- [ ] Flesch Reading Ease score calculation (0-100)
- [ ] Flesch-Kincaid Grade Level calculation
- [ ] Sentence complexity analysis (length, variation, long/short counts)
- [ ] Word complexity analysis (syllables, complex words)
- [ ] Paragraph structure analysis (length, wall-of-text detection)
- [ ] Engagement metrics (questions, lists, subheadings)
- [ ] Target audience mapping from grade level
- [ ] Actionable improvement suggestions
- [ ] FastAPI endpoint `/api/readability/analyze` created
- [ ] Next.js integration endpoint `/api/content/readability` created
- [ ] Readability analysis stored in MongoDB generated_content collection
- [ ] Tests written for readability calculations
- [ ] Code reviewed and approved
- [ ] Merged to dev branch

## Notes

**Implementation Status**: ⏳ Can run independently or after VIP-10209 (SEO analysis)

**Flesch-Kincaid Formulas:**

**Reading Ease (0-100, higher = easier):**
```
Score = 206.835 - 1.015 × (words/sentences) - 84.6 × (syllables/words)

90-100: Very Easy (5th grade)
80-89: Easy (6th grade)
70-79: Fairly Easy (7th grade)
60-69: Standard (8th-9th grade)
50-59: Fairly Difficult (10th-12th grade)
30-49: Difficult (College)
0-29: Very Difficult (College graduate)
```

**Grade Level (U.S. grade required):**
```
Grade = 0.39 × (words/sentences) + 11.8 × (syllables/words) - 15.59

Target: 8-10 for mainstream content
```

**Readability Targets for Content:**
- **Fantasy Football Articles**: 60-70 (8th-9th grade, conversational)
- **News Articles**: 50-60 (10th-12th grade, standard)
- **Technical Guides**: 40-50 (College level, detailed)
- **General Blog Posts**: 70-80 (7th grade, very accessible)

**Sentence Complexity Guidelines:**
- **Optimal Average**: 15-20 words per sentence
- **Good Variation**: 10-30 word range
- **Red Flag**: 3+ sentences over 25 words
- **Engagement**: Include some short sentences (<10 words) for punch

**Word Complexity Guidelines:**
- **Optimal Syllables**: 1.5-2.0 per word on average
- **Complex Words**: <20% should have 3+ syllables
- **Passive Voice**: Minimize (not calculated in this version)

**Paragraph Guidelines:**
- **Optimal Length**: 50-100 words per paragraph
- **Wall of Text**: Avoid 200+ word paragraphs
- **Scannability**: Use lists and subheadings

**Performance Expectations:**
- Analysis Time: <1 second per article
- Extremely fast (no LLM calls)
- Can batch analyze hundreds of articles

**Use Cases:**
- Analyze all generated content automatically
- Compare readability across content types
- Track readability improvements over time
- A/B test different writing styles
- Optimize for specific audience segments

**Integration with SEO (VIP-10209):**
- Readability is 15% of overall SEO score
- Flesch Reading Ease score directly influences SEO
- Can run independently or as part of full SEO analysis

**Next Stories:**
- VIP-10211: Progress Tracking (real-time job status updates)
- VIP-10212: Job Management (retry, cancel, view history)
