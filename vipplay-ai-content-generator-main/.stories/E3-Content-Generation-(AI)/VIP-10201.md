# VIP-10201: Set Up FastAPI for CrewAI Multi-Agent System

**Story ID**: VIP-10201
**Story Type**: Story
**Epic**: E3-Content-Generation-(AI)
**Priority**: High
**Story Points**: 5
**Status**: To Do

## User Story

As a developer, I want FastAPI configured for CrewAI so that I can build multi-agent content generation workflows

## Acceptance Criteria

- [ ] **AC1**: FastAPI service runs independently on port 8000
- [ ] **AC2**: CrewAI library installed and importable
- [ ] **AC3**: Project structure set up for agents, tasks, and tools
- [ ] **AC4**: FastAPI documentation accessible at `/docs`
- [ ] **AC5**: Health check endpoint returns service status
- [ ] **AC6**: Logging configured with structured output

## Technical Details

**Architecture:**
- **FastAPI Role**: AI/ML operations only (CrewAI, Ollama, content generation)
- **Next.js Role**: Orchestration, job management, MongoDB storage, authentication
- **Communication**: Next.js calls FastAPI endpoints, FastAPI returns results

**Project Structure:**
```
api-service/
├── main.py                 # FastAPI application entry point
├── requirements.txt        # Python dependencies
├── .env.example           # Environment template
├── .env                   # Environment variables (gitignored)
├── agents/                # CrewAI agent definitions
│   ├── __init__.py
│   ├── researcher.py     # Content research agent
│   ├── writer.py         # Content writing agent
│   └── seo_optimizer.py  # SEO optimization agent
├── tasks/                 # CrewAI task definitions
│   ├── __init__.py
│   ├── research_tasks.py
│   ├── writing_tasks.py
│   └── seo_tasks.py
├── tools/                 # Custom CrewAI tools
│   ├── __init__.py
│   ├── search_tool.py    # Web search tool
│   └── knowledge_tool.py # Knowledge base query tool
├── routers/               # FastAPI route handlers
│   ├── __init__.py
│   ├── embeddings.py     # Already exists from E2
│   ├── rss.py            # Already exists from E2
│   ├── scrape.py         # Already exists from E2
│   └── content.py        # NEW: Content generation endpoints
├── services/              # Business logic services
│   ├── __init__.py
│   ├── weaviate_service.py  # Already exists from E2
│   ├── ollama_service.py    # NEW: Ollama client wrapper
│   └── crew_service.py      # NEW: CrewAI orchestration
├── models/                # Pydantic models
│   ├── __init__.py
│   ├── embedding_models.py  # Already exists from E2
│   └── content_models.py    # NEW: Content generation models
└── config.py              # Configuration management
```

**Dependencies (`requirements.txt`):**
```txt
# Web Framework
fastapi>=0.109.0
uvicorn[standard]>=0.27.0

# AI & ML
crewai>=0.2.0
crewai-tools>=0.1.0
ollama>=0.1.0

# Existing dependencies from E2
feedparser>=6.0.10
firecrawl-py>=0.0.5
weaviate-client>=4.0.0

# Data Validation
pydantic>=2.5.0
pydantic-settings>=2.1.0

# Utilities
python-dotenv>=1.0.0
aiohttp>=3.9.0

# Testing
pytest>=7.4.0
pytest-asyncio>=0.21.0
httpx>=0.25.0

# Logging
python-json-logger>=2.0.7
```

**FastAPI Main Application (`main.py`):**
```python
"""
VIPContentAI - FastAPI Microservice
Handles AI/ML operations: CrewAI, Ollama, Weaviate
"""

from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
import logging
from contextlib import asynccontextmanager

# Import routers
from routers import embeddings, rss, scrape, content
from services.weaviate_service import weaviate_service
from config import settings

# Configure logging
logging.basicConfig(
    level=settings.LOG_LEVEL,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


@asynccontextmanager
async def lifespan(app: FastAPI):
    """Startup and shutdown events"""
    # Startup
    logger.info("Starting VIPContentAI FastAPI service...")
    await weaviate_service.connect()
    logger.info("Connected to Weaviate")

    yield

    # Shutdown
    logger.info("Shutting down VIPContentAI FastAPI service...")
    await weaviate_service.disconnect()


# Create FastAPI app
app = FastAPI(
    title="VIPContentAI API",
    description="AI-powered content generation microservice",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc",
    lifespan=lifespan
)

# Configure CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.ALLOWED_ORIGINS,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Include routers
app.include_router(embeddings.router)
app.include_router(rss.router)
app.include_router(scrape.router)
app.include_router(content.router)


@app.get("/")
async def root():
    """Root endpoint"""
    return {
        "service": "VIPContentAI FastAPI",
        "version": "1.0.0",
        "status": "running",
        "docs": "/docs"
    }


@app.get("/health")
async def health_check():
    """Health check endpoint"""
    try:
        # Check Weaviate connection
        weaviate_status = weaviate_service.is_ready()

        # Check Ollama connection (to be implemented in VIP-10203)
        ollama_status = True  # Placeholder

        return JSONResponse(
            status_code=200 if (weaviate_status and ollama_status) else 503,
            content={
                "status": "healthy" if (weaviate_status and ollama_status) else "degraded",
                "services": {
                    "weaviate": "up" if weaviate_status else "down",
                    "ollama": "up" if ollama_status else "down",
                }
            }
        )
    except Exception as e:
        logger.error(f"Health check failed: {e}")
        return JSONResponse(
            status_code=503,
            content={"status": "unhealthy", "error": str(e)}
        )


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        "main:app",
        host=settings.API_HOST,
        port=settings.API_PORT,
        reload=settings.RELOAD
    )
```

**Configuration (`config.py`):**
```python
"""Application configuration"""

from pydantic_settings import BaseSettings
from typing import List


class Settings(BaseSettings):
    """Application settings loaded from environment variables"""

    # API Configuration
    API_HOST: str = "0.0.0.0"
    API_PORT: int = 8000
    RELOAD: bool = True

    # Ollama Configuration
    OLLAMA_BASE_URL: str = "http://localhost:11434"
    DEFAULT_MODEL: str = "llama3.1:8b"
    QUALITY_MODEL: str = "llama3.1:70b"
    EMBEDDING_MODEL: str = "nomic-embed-text"

    # Model Parameters
    MAX_TOKENS: int = 4096
    TEMPERATURE: float = 0.7
    TOP_P: float = 0.9

    # Weaviate Configuration
    WEAVIATE_URL: str = "http://localhost:8080"

    # Firecrawl Configuration
    FIRECRAWL_API_KEY: str = ""

    # AWS SES Configuration
    AWS_ACCESS_KEY_ID: str = ""
    AWS_SECRET_ACCESS_KEY: str = ""
    AWS_SES_REGION: str = "ap-southeast-2"
    AWS_SES_FROM_EMAIL: str = "noreply@vipcontentai.com"
    AWS_SES_FROM_NAME: str = "VIPContentAI"

    # CORS Configuration
    ALLOWED_ORIGINS: List[str] = ["http://localhost:3000", "http://127.0.0.1:3000"]

    # Logging
    LOG_LEVEL: str = "INFO"

    class Config:
        env_file = ".env"
        case_sensitive = True


settings = Settings()
```

**Placeholder Content Router (`routers/content.py`):**
```python
"""
Content generation router
Will be implemented in subsequent stories
"""

from fastapi import APIRouter, HTTPException
from pydantic import BaseModel

router = APIRouter(prefix="/api/content", tags=["content"])


class GenerateRequest(BaseModel):
    """Content generation request (placeholder)"""
    mode: str  # topic, keywords, trends, spin
    input_text: str
    word_count: int = 1500


class GenerateResponse(BaseModel):
    """Content generation response (placeholder)"""
    success: bool
    job_id: str
    message: str


@router.post("/generate", response_model=GenerateResponse)
async def generate_content(request: GenerateRequest):
    """
    Generate content using CrewAI (placeholder)
    Will be fully implemented in VIP-10204-10207
    """
    raise HTTPException(
        status_code=501,
        detail="Content generation not yet implemented. See VIP-10204-10207"
    )
```

**Startup Scripts:**

Already exist in project root:
- `start-fastapi.ps1` (Windows)
- Manual: `cd api-service && uvicorn main:app --reload`

**Docker Support:**

Create `api-service/Dockerfile`:
```dockerfile
FROM python:3.10-slim

WORKDIR /app

# Install dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application
COPY . .

# Expose port
EXPOSE 8000

# Run application
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

**Testing:**
1. Start FastAPI: `cd api-service && uvicorn main:app --reload`
2. Access docs: http://localhost:8000/docs
3. Test health check: http://localhost:8000/health
4. Verify all routers loaded (embeddings, rss, scrape, content)
5. Test CORS with Next.js requests

**Integration with Next.js:**

Next.js will call FastAPI endpoints:
```typescript
// Example from Next.js
const FASTAPI_URL = process.env.FASTAPI_URL || 'http://localhost:8000';

const response = await fetch(`${FASTAPI_URL}/api/content/generate`, {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    mode: 'topic',
    input_text: 'Fantasy Football Week 10 Analysis',
    word_count: 1500
  })
});
```

## Definition of Done

- [ ] FastAPI service starts successfully on port 8000
- [ ] CrewAI library installed and importable
- [ ] Project structure created with agents/, tasks/, tools/ folders
- [ ] Configuration management working (config.py with pydantic-settings)
- [ ] Health check endpoint returns service status
- [ ] FastAPI docs accessible at http://localhost:8000/docs
- [ ] Logging configured with INFO level
- [ ] Existing E2 routers still functional (embeddings, rss, scrape)
- [ ] Placeholder content router created
- [ ] Docker support added (Dockerfile)
- [ ] Tested startup and health check
- [ ] Code reviewed and merged to dev branch

## Notes

**Implementation Status**: ⏳ Partial (E2 infrastructure exists)

**What Already Exists from E2:**
- ✅ FastAPI main.py basic structure
- ✅ Routers: embeddings.py, rss.py, scrape.py
- ✅ Services: weaviate_service.py
- ✅ Models: embedding_models.py
- ✅ Environment configuration

**What Needs to be Added:**
- CrewAI library and dependencies
- agents/, tasks/, tools/ folder structure
- config.py for centralized configuration
- routers/content.py placeholder
- Enhanced health check
- Docker support

**Architecture Clarity:**
- ❌ FastAPI does NOT handle authentication (Next.js does)
- ❌ FastAPI does NOT store data in MongoDB (Next.js does)
- ✅ FastAPI handles AI/ML operations (CrewAI, Ollama, embeddings)
- ✅ FastAPI exposes REST endpoints for Next.js to call
- ✅ FastAPI returns results, Next.js stores in MongoDB

**Next Stories:**
- VIP-10202: Configure CrewAI agents (researcher, writer, SEO)
- VIP-10203: Ollama integration and client wrapper
- VIP-10204-10207: Implement content generation modes
